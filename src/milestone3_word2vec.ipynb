{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Constants/parameters\n",
    "SUBMISSION_ID = 73\n",
    "OUT_PATH = '../results/'\n",
    "IN_PATH = '../data/'\n",
    "WORD_EMBEDDINGS_PATH = '../word_embeddings/model_1/'\n",
    "MODEL_NAME = 'model_sg_1_size_200_min_count_2_negative_10_window_10'\n",
    "TARGET_CLASSES = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(IN_PATH + 'train.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_preprocessed_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as fi:\n",
    "        data = json.load(fi)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = load_preprocessed_data(IN_PATH + 'train_preprocessed.json')\n",
    "test_preprocessed = load_preprocessed_data(IN_PATH + 'test_preprocessed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load(WORD_EMBEDDINGS_PATH + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Representation of comments as average of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_comments_embeddings(comments, word_emb_dims=200):\n",
    "    comments_embeddings = np.zeros((len(comments), word_emb_dims))\n",
    "    comments_emb_nr = [0 for _ in range(len(comments))]\n",
    "    \n",
    "    for i in tqdm(range(len(comments))):\n",
    "        for word in comments[i]:\n",
    "            if model.wv.vocab.has_key(word):\n",
    "                comments_embeddings[i] += model.wv[word]\n",
    "                comments_emb_nr[i] += 1\n",
    "\n",
    "    # a comment is represented by the average of word_embeddings\n",
    "    for i in range(len(comments_embeddings)):\n",
    "        if comments_emb_nr[i] != 0:\n",
    "            comments_embeddings[i] = comments_embeddings[i] / comments_emb_nr[i]\n",
    "\n",
    "    return comments_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:20<00:00, 7797.19it/s]\n",
      "100%|██████████| 153164/153164 [00:18<00:00, 8306.25it/s]\n"
     ]
    }
   ],
   "source": [
    "train_comments = get_comments_embeddings(train_preprocessed, 200)\n",
    "test_comments = get_comments_embeddings(test_preprocessed, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_comments\n",
    "train_y = train_df[TARGET_CLASSES].as_matrix()\n",
    "test_x = test_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_classifier(train_x, train_y, test_x, method='LinearSVC'):\n",
    "    print('---svm_classifier---')\n",
    "    scaler = preprocessing.StandardScaler().fit(train_x)\n",
    "    train_x = scaler.transform(train_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "\n",
    "    pred = np.zeros((test_x.shape[0], len(TARGET_CLASSES)))\n",
    "\n",
    "    for i in tqdm(range(len(TARGET_CLASSES))):\n",
    "        #print('class {}'.format(i))\n",
    "        classifier = None\n",
    "        if method == 'LinearSVC':\n",
    "            classifier = svm.LinearSVC()\n",
    "        elif method == 'SVC':\n",
    "            classifier = svm.SVC(C=1.3)\n",
    "\n",
    "        classifier.fit(train_x, train_y[:,i])\n",
    "        pred[:,i] = classifier.predict(test_x)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_classifier(train_x, train_y, test_x):\n",
    "    print('---nb_classifier---')\n",
    "    preds = np.zeros((test_x.shape[0], len(TARGET_CLASSES)))\n",
    "\n",
    "    for i in tqdm(range(len(TARGET_CLASSES))):\n",
    "        #print('step: {}'.format(i))\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(train_x, train_y[:,i])\n",
    "        preds[:,i] = classifier.predict_proba(test_x)[:,1]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(train_x, train_y, test_x):\n",
    "    print('---logistic_regression---')\n",
    "    preds = np.zeros((len(test_x), len(TARGET_CLASSES)))\n",
    "\n",
    "    for i in tqdm(range(len(TARGET_CLASSES))):\n",
    "        lr_model = LogisticRegression(C=4, dual=True)#, class_weight='balanced')\n",
    "        lr_model.fit(train_x, train_y[:,i])\n",
    "        preds[:,i] = lr_model.predict_proba(test_x)[:,1]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification(train_x, train_y, test_x, classifier='NB'):\n",
    "    preds = []\n",
    "    if classifier == 'SVM':\n",
    "        preds = svm_classifier(train_x, train_y, test_x, method='LinearSVC')\n",
    "    elif classifier == 'NB':\n",
    "        preds = nb_classifier(train_x, train_y, test_x)\n",
    "    elif classifier == 'LR':\n",
    "        preds = logistic_regression(train_x, train_y, test_x)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(pred, in_path, out_path):\n",
    "    print('---write_results---')\n",
    "    res_df = pd.read_csv(in_path)\n",
    "\n",
    "    idx = 0\n",
    "    for x in pred:\n",
    "        # TODO: x.toarray()[0] for nb_classifier output\n",
    "        #       x for svm_classifier output\n",
    "        probs = x #x.toarray()[0]\n",
    "        \n",
    "        for k in range(len(TARGET_CLASSES)):\n",
    "            res_df[TARGET_CLASSES[k]].set_value(idx, probs[k])\n",
    "        \n",
    "        idx += 1\n",
    "    \n",
    "    res_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(train_x, train_y, test_x, classifier, in_path, out_path):\n",
    "    preds = classification(train_x, train_y, test_x, classifier)\n",
    "    write_results(preds, in_path, out_path)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    experiment_names = ['SVM', 'NB', 'LR']\n",
    "    preds = list()\n",
    "    \n",
    "    for i in tqdm(range(len(experiment_names))):\n",
    "        preds.append(run_experiment(train_x, train_y, test_x, \n",
    "                                    experiment_names[i], \n",
    "                                    IN_PATH + 'sample_submission.csv', \n",
    "                                    OUT_PATH + 'submission_' + str(SUBMISSION_ID + i) + '.csv'))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---svm_classifier---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [01:36<08:03, 96.71s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [03:11<06:23, 95.90s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [04:48<04:48, 96.13s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [06:17<03:08, 94.42s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [08:01<01:36, 96.27s/it]\u001b[A\n",
      "100%|██████████| 6/6 [09:39<00:00, 96.59s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---write_results---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [09:44<19:28, 584.28s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---nb_classifier---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.29it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:01<00:03,  1.29it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:02<00:02,  1.28it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.27it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.27it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.27it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---write_results---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [09:53<04:56, 296.84s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---logistic_regression---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [00:13<01:09, 13.96s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:27<00:55, 13.79s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:40<00:40, 13.62s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:52<00:26, 13.21s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [01:05<00:13, 13.05s/it]\u001b[A\n",
      "100%|██████████| 6/6 [01:18<00:00, 13.00s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---write_results---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:15<00:00, 225.31s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = run_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
